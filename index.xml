<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kent Sommer</title>
    <link>https://kentsommer.xyz/</link>
    <description>Recent content on Kent Sommer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 03 Feb 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://kentsommer.xyz/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Journey Through Platforms</title>
      <link>https://kentsommer.xyz/blog/a-journey-through-platforms/</link>
      <pubDate>Fri, 03 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/a-journey-through-platforms/</guid>
      <description>&lt;p&gt;So, it has been some time since my last post&amp;hellip; Before I get into the fun stuff (well&amp;hellip; fun for me anyways), let me give you a bit of a life update! Having already finished 1/4th of my masters, I can say with confidence that I am really happy that I decided to continue on and get an advanced degree. I&amp;rsquo;m able to work with world-class researchers on amazing topics doing work that has the potential to drastically improve people&amp;rsquo;s lives. If someone would have told me when I was in high school that this is the type of work I would be doing, I probably would have laughed at them. Not because I wouldn&amp;rsquo;t want to be doing it, but simply because at that time I thought there was no way I possibly could. It has taken until probably just a month or two ago for me to finally realize I&amp;rsquo;m actually capable of contributing meaningfully to research. Why it took so long to shake the constant feeling of imposters syndrome is something I probably will never know. I&amp;rsquo;ve struggled a lot with self-confidence in the past but just being in Korea and constantly overcoming challenges both academic and otherwise has really helped to put things into perspective and pushed me to grow a lot as a person.&lt;/p&gt;

&lt;p&gt;Since finals have finished I&amp;rsquo;ve been working in the lab on a few projects, giving seminars on deep learning, and contributing back a bit to the open source community. I&amp;rsquo;m not actually sure what I am allowed to say publicly about the projects so I won&amp;rsquo;t go into much detail on those, however, I get to work with the Hubo lab (&lt;a href=&#34;https://www.google.co.kr/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=0ahUKEwiX-8_75_zRAhUIGJQKHU7rB8oQtwIIGDAA&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DBGOUSvaQcBs&amp;amp;usg=AFQjCNGsgOcG0NXTfl1TzgClCFSjn01elw&amp;amp;sig2=285L1YiiOgTdxRy52SL1ZQ&amp;amp;bvm=bv.146094739,d.dGc&#34;&gt;the lab that won the DARPA 2015 Robotics Challenge&lt;/a&gt;) as well as a group from Seoul National University. The seminars have actually been a blast so far, and of course teaching always (most of the time) forces you to better understand the material yourself which is obviously beneficial to me. My professor suggested that three of us in the lab go through a deep learning textbook in detail and present on all of the chapters. Partially to help bring anyone in the lab who maybe wasn&amp;rsquo;t very familiar up to speed a bit, but also to just really solidify all the concepts for those of us giving the seminars. As for the open source work I&amp;rsquo;ve been doing, none of the code is novel, but rather helps to improve access to deep learning models by implementing them in more accessible frameworks (Keras for example).&lt;/p&gt;

&lt;p&gt;The first two open source releases I made were implementations of a model called PoseNet. PoseNet was based on GoogLeNet and works by replacing the final and auxiliary fully connected layers (used for image classification) with regression outputs. When I say regression I mean that it outputs continuous values instead of a number within some set range (say 0 to 1000 where each number represents a class as in imagenet). As I said before I have two implementations available for PoseNet (the original author also has a Caffe implementation):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kentsommer/keras-posenet&#34;&gt;Keras based implementation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kentsommer/tensorflow-posenet&#34;&gt;Tensorflow based implementation&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More recently, after reading through Google&amp;rsquo;s paper on their latest version of the Inception architecture (Inception-V4), I decided it would be a good exercise to try and implement the model in Keras and port the weights that they released for TFslim (Tensorflow slim). This ended up taking up more of my time than I had originally intended, however, I learned a ton on the journey.&lt;/p&gt;

&lt;p&gt;(Just a quick warning, the rest of this post will likely be rather technical although I will do my best to make it easy to understand)&lt;/p&gt;

&lt;p&gt;The first large hurdle was that the pre-trained weights that Google released were in a ckpt (checkpoint) file which is the standard for Tensorflow but is also kind of a pain to use if you want to just get at the data (after all, we really just need the weights as arrays). After hacking together a really ugly solution to read the weights from the ckpt file and set them layer by layer into the Keras implementation of the model, I ran into my first bug (one that would drive me nuts for the better part of a day). No matter what I tried, the model always predicted the class of my test image horribly wrong (would classify an elephant as a toilet, etc&amp;hellip;). As I become more frustrated I finally started to hack up my model implementation to try and fix the issue. There ended up actually being three weird bugs:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The first was that I had somehow missed that Batch Normalization was supposed to be applied after EVERY convolution layer.&lt;/li&gt;
&lt;li&gt;The second was that for whatever reason, applying rectified linear unit activation before Batch Normalization drastically hurt performance. While the original papers that used Batch Normalization apply the layer activations after it, recent trends have been to apply activations first and the results &amp;ldquo;should&amp;rdquo; be really similar no matter what the order is. My guess is that I&amp;rsquo;m missing some information on why this caused such a large performance hit, so now that I&amp;rsquo;ve got everything working I&amp;rsquo;ll do some research on that topic.&lt;/li&gt;
&lt;li&gt;The third and possibly most perplexing is that when using Batch Normalization, the biases in convolutional layers technically become &amp;ldquo;useless in the calculation.&amp;rdquo; So, I expected that allowing the biases in the convolutional layers to be initialized would not throw off the predictions by much (if at all). It turns out&amp;hellip; it does. Keras makes it easy luckily to simply remove the biases from convolutional layers, so after setting the &lt;code&gt;bias=False&lt;/code&gt; flag, everything finally worked.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After hacking together some performance testing scripts to validate the accuracy of the model against the imagenet validation dataset, I was finally able to show equal quality results to that of the original model. And while I would like to say that was the end of it&amp;hellip; it wasn&amp;rsquo;t. Because Keras supports two backends (Theano and Tensorflow), and Theano implements the convolution operation differently than Tensorflow, the weights needed to be ported from the Tensorflow backend to the Theano backend. Converting the convolution kernels ends up being really easy though:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from keras import backend as K
from keras.utils.np_utils import convert_kernel

for layer in model.layers:
   if layer.__class__.__name__ in [&#39;Convolution1D&#39;, &#39;Convolution2D&#39;]:
      original_w = K.get_value(layer.W)
      converted_w = convert_kernel(original_w)
      K.set_value(layer.W, converted_w)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This change allows you to switch the backends and use Theano! However, since Theano typically takes in images with the dimension ordering (channels, width, height), and Tensorflow takes in images with dimension ordering (width, height, channels) it is also necessary to do some weight matrix transposing magic to make everything work. This process is also pretty simple though:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for index, layer in enumerate(layers):
    if th_layer.__class__.__name__ in conv_classes:
        weights = weights_list[index]
        weights[0] = weights[0].transpose((3,2,0,1))
        layer.set_weights(weights)
        print(&#39;converted &#39;, layer.name)
    else:
        layer.set_weights(weights_list[index])
        print(&#39;set: &#39;, layer.name)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only bit that tripped me up initially is that the author or Keras had mentioned in a &lt;a href=&#34;https://groups.google.com/forum/#!searchin/keras-users/convert$20weights$20tensorflow%7Csort:relevance/keras-users/E1W4HpuxxFw/B2DCDluTCwAJ&#34;&gt;google forums post&lt;/a&gt; that it is also necessary to row shuffle the weights of the first fully connected layer. I ended up not needing to do this, and I&amp;rsquo;m not exactly sure why it was mentioned as necessary originally. However, it did cause me to go on a wild goose chase looking for a solution to a problem I didn&amp;rsquo;t have. Finally, I deduced the row shuffling was unnecessary, fixed the last (stupidly simple) remaining bug and everything &amp;ldquo;just worked.&amp;rdquo; Given a picture of an elephant as input, for instance, you would get the following (assuming you use the same image of an elephant I did):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Loaded Model Weights!
Class is: African elephant, Loxodonta africana
Certainty is: 0.868498
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you are interested in playing around with the model (I promise it doesn&amp;rsquo;t bite!), feel free to get it &lt;a href=&#34;https://github.com/kentsommer/keras-inceptionV4&#34;&gt;from here&lt;/a&gt;! The takeaway from this whole adventure for me has been a much better understanding of the implementation differences between Theano and Tensorflow. Although frustrating at times, it was a really fun experience and if I have some more free time I wouldn&amp;rsquo;t mind porting some other popular models to Keras or any other framework. So&amp;hellip; if you have any ideas, leave a comment or shoot me an email and I&amp;rsquo;d be happy to look into porting it!&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s all, for now, folks!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Winter is Coming</title>
      <link>https://kentsommer.xyz/blog/winter-is-coming/</link>
      <pubDate>Fri, 28 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/winter-is-coming/</guid>
      <description>&lt;p&gt;As I groggily walked out of my dorm and into the crisp Fall air this morning it became readily apparent that Winter was indeed on its way. It is that extra little bite to the air that wasn&amp;rsquo;t present a few days ago. Midterms have come and gone uneventfully which in my mind is a good thing. I did find out a rather crazy fact about tests for undergraduates here at KAIST though&amp;hellip; apparently, most tests give you as much time as you want. Sounds good, right? Well&amp;hellip; sort of? Turns out that unlimited time starts at 7PM so its a battle between staying awake and finishing the test. I&amp;rsquo;ve walked through the Computer Science building here and twice now have seen some lingering students still working on their test at 7:30-8:00AM. Its moments like those that make me glad I&amp;rsquo;m through the brunt of my coursework for my life. Don&amp;rsquo;t get me wrong, I love learning and obviously wouldn&amp;rsquo;t have come to grad school if I didn&amp;rsquo;t. It just the darn tests&amp;hellip;&lt;/p&gt;

&lt;p&gt;I realize it has been a while since I&amp;rsquo;ve posted anything and mostly that is because I haven&amp;rsquo;t had much to talk about other than my research which is on my brain &lt;sup&gt;24&lt;/sup&gt;&amp;frasl;&lt;sub&gt;7&lt;/sub&gt;. So, writing about it is pretty much the last thing I want to do. As you may have noticed, the site has changed pretty drastically, which is due to switching web-hosts and needing to put things back together from scratch. Luckily I happened upon a pretty awesome static website generator called Hugo which also just so happens to support Github Pages which means no more paying for a web host. Oh and Github Pages supports custom domains for free so I could keep the same domain! (obviously, you have to supply your own domain but that&amp;rsquo;s like $12 a year).&lt;/p&gt;

&lt;p&gt;On a totally different note, I have sort of a fun project planned for my Information Security class that I&amp;rsquo;m sure some of you might find interesting. So, the accelerometers on mobile phones these days are actually getting pretty accurate and luckily for me (and this project), are not considered to produce private data. That is, accessing accelerometer data doesn&amp;rsquo;t require a privilege request. Since no request is necessary, it seemed to lend itself well as a data source for a side channel attack or SCA. An SCA, put very simplistically, is an attack that works by using unsecured data and trying to determine something about a secure system that is producing it. In this case what I&amp;rsquo;m aiming to recover is press locations on the screen in real time. While this may not sound like much, it could essentially allow for background keylogging that &amp;ldquo;technically&amp;rdquo; doesn&amp;rsquo;t break any rules and doesn&amp;rsquo;t require escalated privileges. Training a machine learning model to classify accelerometer readings into screen press locations takes a lot of data though and that is where the second part of my project comes in. Simply mask the data collection required to train the model for each individual phone as a game. Basically&amp;hellip; make a knockoff osu!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;osu! is a freeware rhythm game developed by Dean &amp;ldquo;peppy&amp;rdquo; Herbert, originally for Microsoft Windows. It is written in C# on the .NET Framework. The game has also been ported to OS X, iOS, Android, and Windows Phone.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since the app knows where a user is pressing and can record accelerometer information at the same time, data is collected unknowingly and efficiently. After &amp;ldquo;enough&amp;rdquo; data has been collected it can be sent off to be trained on. Once trained, the weights are then sent back to the app on the phone and keylogging can commence. What I&amp;rsquo;m aiming to show through this project is that accelerometer data should probably be hidden behind privilege escalations and not just available for any background service to use freely as classification techniques are getting advanced enough to infer knowledge that was previously not possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://kentsommer.xyz/projects/1/</link>
      <pubDate>Sun, 02 Oct 2016 22:55:05 -0400</pubDate>
      
      <guid>https://kentsommer.xyz/projects/1/</guid>
      <description>&lt;p&gt;TEST&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://kentsommer.xyz/projects/</link>
      <pubDate>Sun, 02 Oct 2016 22:55:05 -0400</pubDate>
      
      <guid>https://kentsommer.xyz/projects/</guid>
      <description>&lt;section id=&#34;projects&#34;&gt;
  &lt;div class=&#34;container&#34;&gt;
    &lt;h3&gt;Projects&lt;/h3&gt;
    &lt;div class=&#34;panel panel-default&#34;&gt;
      &lt;div class=&#34;panel-body&#34;&gt;
      &lt;h5&gt;
        &lt;i class=&#34;fa fa-github&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&lt;a href=&#34;https://github.com/kentsommer/2D-EKF-SLAM&#34;&gt;2D Extendend Kalman Filter Based SLAM&lt;/a&gt;&lt;/strong&gt; &lt;br&gt;
        &lt;i class=&#34;fa fa-cog&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;SLAM_report.pdf&#34; target=&#34;_blank&#34;&gt;Paper&lt;/a&gt; &lt;br&gt;
        - This project serves as a robust simultaneous localization and mapping stack written for use on the Pioneer 3-DX with a SICK LMS-200 laser scanner in a pre-determined environment. It uses the extended kalman filter approach to SLAM which until recently was the go-to method of implementing SLAM. It consists of three main parts: motion controller, feature detector, and kalman filter. The motion controller runs in a separate thread to allow for faster updates and follows the following logic: turn left whenever possible, otherwise continue straight and align to the walls on either side. The feature detector works by applying the Hough Transform to extract lines which are subsequently processed down into segments and then corners which are used as features. The kalman filter is a standard implementation and uses the Mahalanobis distance algorithm to determine if landmarks are new or are being re-detected. 
      &lt;/h5&gt;
      &lt;h5&gt;
        &lt;i class=&#34;fa fa-github&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&lt;a href=&#34;https://github.com/kentsommer/obstacle_detection&#34;&gt;3D Obstacle Detection&lt;/a&gt;&lt;/strong&gt; &lt;br&gt;
        - This project serves as an obstacle detection stack with the goal of being efficient enough to run on relatively low powered hardware. The approach starts with an unfiltered pointcloud (from an 3D sensor). The first step is a passthrough filter which cuts off points further away in the Z direction than would be visible given the starting camera angle. Next I applied a voxel grid downsample to further help reduce the number of points. This was followed by performing statistical outlier removal on the points that didn&#39;t fit the set model (not enough points close enough together). The next step was ground extraction which used the following: RANSAC plane fitting, group plane inlier extraction, ground plane outlier extraction, convex hull creation from projected ground inliers, and finally outlier extraction from above the convex hull. The output of this could then be passed on to the path planning system. It is able to accurately detect objects as thin as 1.2 cm that are on the floor. 
      &lt;/h5&gt;
        &lt;h5&gt;
        &lt;i class=&#34;fa fa-github&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&lt;a href=&#34;https://github.com/kentsommer/3DObjectReconstruction&#34;&gt;3D Object Reconstruction&lt;/a&gt;&lt;/strong&gt; &lt;br&gt;
        &lt;i class=&#34;fa fa-cog&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;3D+Model+Reconstruction+Paper.pdf&#34; target=&#34;_blank&#34;&gt;Individual Paper&lt;/a&gt; &lt;br&gt;
        &lt;i class=&#34;fa fa-cog&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;a href=&#34;3D+Model+Reconstruction+Group+Paper.pdf&#34; target=&#34;_blank&#34;&gt;Group Paper&lt;/a&gt; &lt;br&gt;
        - This served as my final project for CSCI 5561 (Computer Vision). Using a single camera with pictures taken at multiple angles, this project allowed for a dense reconstruction of the original object. The project relies heavily on the principle of shape from silhouettes and voxel carving. It works by first extracting a silhouette of the object at all camera angles. These binary images are then used to carve away a bounding box of the object using shape from silhouettes. Finally, the carved model is then retextured by matching the 3D model points to their respective original images. 
      &lt;/h5&gt;
      &lt;h5&gt;
        &lt;i class=&#34;fa fa-cog&#34;&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;strong&gt;&lt;a href=&#34;Sodoku+AI+Research+Paper.pdf&#34;&gt;Sudoku AI Research Paper&lt;/a&gt;&lt;/strong&gt; &lt;br&gt;
        - This paper was my final research paper for CSCI 4511W (Introduction to Artificial Intelligence). It examines various approaches to building an AI for Sudoku.
      &lt;/h5&gt;


      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tensors, Baseball, and a whole lot of fun</title>
      <link>https://kentsommer.xyz/blog/tensors-baseball-fun/</link>
      <pubDate>Tue, 20 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/tensors-baseball-fun/</guid>
      <description>&lt;p&gt;It has taken a while for me to really feel settled in here, but I think I&amp;rsquo;ve finally crossed that line and I&amp;rsquo;m starting to feel really blessed to be here.&lt;/p&gt;

&lt;p&gt;The last couple weeks have been an absolute blast and given the fact that I basically get to build cool things every day, so should the rest of my time here. As far as classes go&amp;hellip; I can&amp;rsquo;t really pick out many differences so far compared to the structure of similar graduate level courses in the US. Perhaps in some classes, there is a bit more emphasis on fact memorization, but even that seems to be within the bounds of normal. I&amp;rsquo;ve mentioned this to a few people now whenever they ask what the big differences between the US and Korea are, but it is actually really hard to say. Once you step off the plane, everything is so radically different and yet so easy to become accustomed to that you hardly realize the changes in lifestyle or cultural behavior. In that sense, I think Korea is a great tourist destination not because it is easy to get around without knowing the language (it isn&amp;rsquo;t&amp;hellip; it is actually pretty hard), but simply because you get used to the radical differences extremely quickly.&lt;/p&gt;

&lt;p&gt;Now, you probably read the title of this post and by this point, you are thinking what in the world does any of this have to do with tensors, to which the obvious answer is&amp;hellip; absolutely nothing. But, let&amp;rsquo;s change that. Not too terribly long ago, Google released its machine learning library &amp;ldquo;TensorFlow&amp;rdquo;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;TensorFlowâ„¢ is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This library is not dissimilar to other machine learning libraries such as Caffe, Theano, etc., however, since it is new and probably most importantly required for use in a homework assignment, it is the library I am using at the moment. Machine learning has recently gotten a lot of attention in the area of Computer Vision for achieving really awesome results for tasks such as object/place recognition, and image captioning. My foray into TensorFlow (due to the homework assignment) has been focused on image retrieval using CNN (Convolutional Neural Network) features. Given a pre-trained VGG16 network as shown here:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://kentsommer.xyz/postimgs/vgg16.png&#34; alt=&#34;alt text&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If you use the second 1x1x4096 fully connected layer (fc2) as a feature vector on a given query image, and then again pull out the fc2 feature vector on each image in some set that is known to contain similar or identical images (even those taken at different angles or scales), it becomes possible to match the feature vectors (using some similarity measurement) and retrieve pictures of the same image or similar ones. While this approach is naive, and if running solely on a CPU it is also stupidly slow (for 250 query images and a test set of 1000 it takes 29.86 hours to run), it still manages to achieve very acceptable results. Do note, this would be orders of magnitude faster given a GPU with enough vRAM, however, my measly 2GB card runs out of memory on this task. All of that being said, the precision achieved is actually impressive. It is able to achieve 92% accuracy when trying to match the closest 4 images in the test dataset to some image category in the query dataset.&lt;/p&gt;

&lt;p&gt;While this work is barely scratching the surface of what is currently possible using machine learning, it is still extremely impressive compared with the past work in image matching using hand crafted features (SIFT, SURF, ORB, etc).&lt;/p&gt;

&lt;p&gt;Source code for the above: &lt;a href=&#34;https://github.com/kentsommer/VGG16-Image-Retrieval&#34;&gt;https://github.com/kentsommer/VGG16-Image-Retrieval&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now&amp;hellip; baseball. Anyone who knows me is aware of the fact that I&amp;rsquo;ve never particularly liked watching baseball mainly due to the fact that there just simply isn&amp;rsquo;t a heck of a lot happening most of the time. I&amp;rsquo;m sure it is fun to play, just not the quickest paced spectator sport. Well, let me tell you, watching baseball in Korea flips that idea on its head. While the game itself is still slow, you can&amp;rsquo;t focus on that most of the time because the bits where nothing is happening are all filled with syncronized cheering, chanting, and dancing. Every time &amp;ldquo;your team&amp;rdquo; is up to bat, the cheering man (for lack of a better description) gets up on a stage and starts directing. These chants/cheers are also distinctly different from the US style of cheerleading songs mainly because they are very specific to whoever is batting. Each player has their own &amp;ldquo;theme-song&amp;rdquo; if not multiple songs. Everyone, and I mean EVERYONE sings along and waves their hands about. It is a blast and the energy is greater than that of almost any professional sports game I&amp;rsquo;ve been to in the US (granted its a pretty small sample size&amp;hellip;). If you ever come to Korea make sure to try to catch a baseball game (and bring a Korean friend with who can help guide you with what you are supposed to be chanting) even if you aren&amp;rsquo;t a huge fan of the game normally. Here is a short clip of the crowd after the team we were cheering for hit a homerun to finish off the game and win (and yes I know it is stupid that I recorded it vertically but hey it is in 4K!):&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/-3izxpVzTZM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Reality Sets In</title>
      <link>https://kentsommer.xyz/blog/reality-sets-in/</link>
      <pubDate>Wed, 31 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/reality-sets-in/</guid>
      <description>&lt;p&gt;Well, I&amp;rsquo;m finally here. I think often I let myself get caught up in the negative aspects of a new place or experience so in this post I will focus on everything good here at KAIST so far. The transition to living in a dorm after having my own space for the better part of my life has actually been very smooth so far. I have an awesome roommate, and the dorm facilities are clean and bright. Sadly, this dorm does not have private bathrooms or showers, however, the shared spaces that it does have are very nice. Cafeteria food is good and extremely cheap (3,000 - 4,000 krw / $2.8-$3.7 per meal), and while it definitely isn&amp;rsquo;t restaurant living, it is cheaper than any comparable meal I could make myself.&lt;/p&gt;

&lt;p&gt;The weather has been particularly wonderful the past couple of days as orientation has come and gone. Speaking of which, the orientation program was very well put together and provided a great balance of important necessary information as well as campus life improvement tips. It also consisted of talking with a few different current M.S. and Ph.D. students which was very helpful while remaining borderline terrifying. Moving forward, I think the most important aspect for me will be making sure to carve out time to keep myself sane for the many hours of incoming lab and course work. Letting sleep hours take a hit is an easy trap to fall into, and while some students swear its necessary, I think there are other ways to deal with a growing workload that are less burnout inducing.&lt;/p&gt;

&lt;p&gt;On the topic of lab work / research, I am at least very excited about moving forward with the research ideas I have ready. Mixing the current advancements in Convolutional Neural Networks (CNN&amp;rsquo;s) for place and object recognition with a topological approach to localization (where the map is represented as a graph with spaces being nodes and connections between the spaces being edges) could eventually make robots much easier to work with in a home or similar scenario. Imagine being able to guide a robot the same way you would guide a person to your kitchen sink, refrigerator, or anywhere else in the house instead of telling it to move to a specific point on a map that you have to indicate.&lt;/p&gt;

&lt;p&gt;I will be meeting with my professor soon to discuss my ideas for my research as well as meeting the lab for the first time. It is an exciting, though terrifying, time in my life, and I look forward to being able to push the boundaries of what is possible and come out on the other side of this journey a stronger person. If anyone reading this would like to get in touch, please do not hesitate to do so! My kakao talk id is: kentsommer (kakao talk is THE messaging app in Korea), otherwise feel free to email me or simply leave a comment on any of the blog posts.&lt;/p&gt;

&lt;p&gt;Till next time!
- Kent&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Curious Case of Dunkin Doughnuts</title>
      <link>https://kentsommer.xyz/blog/the-curious-case-of-dunkin-doughnuts/</link>
      <pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/the-curious-case-of-dunkin-doughnuts/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s 8:45 in the morning, sweat is already dripping down my back as the heat from the past few weeks still hasn&amp;rsquo;t cleared. Suddenly a familiar but unplaceable tune starts playing over the subway station speakers signaling that the train is almost here. As I, and everyone else, are jostled into place by the crowed moving onto the train I realize I haven&amp;rsquo;t had breakfast yet. Where do I finally end up you might ask? Well&amp;hellip; Dunkin Doughnuts of course! Now I know what you are all probably thinking&amp;hellip; Dunkin Doughnuts isn&amp;rsquo;t that great and in fact, may earn the title of pretty stinking bad. So, why would you go to the trouble?. Well, here is a little secret, it has basically nothing in common with the US version of the same store (other than both selling coffee and some semblance of treats). The doughnuts are actually delicious unlike their US counterparts, and the coffee is something comparable to Starbucks (that is to say not fantastic, but certainly not bad). How the US ended up with the subpar version is beyond me and to be honest rather outside of the scope of this blog, however, it does make you wonder.&lt;/p&gt;

&lt;p&gt;While I did have a blast meandering around coffee shops and visiting a few popular places in Seoul, most of my time was spent on much less interesting topics like paperwork&amp;hellip; That being said, as of about six hours ago from publishing time of this post, I have finally been approved for my Alien Registration Card! It won&amp;rsquo;t come for another 2-3 weeks, but it is a huge burden off my back knowing that it is finished.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m now a little under one week out from my arrival on campus at KAIST. I am very grateful for the time I got to spend in Seoul before I start my time as a student again. I know I touched on this topic during my very first post, but it is pretty crazy to think about how I ended up here. Everything has happened in what has felt like the blink of an eye, and while some of it has been stressful the majority of moments leading up to this point have been overwhelmingly positive. Never in my wildest dreams would I have expected to end up where I am now only three short years ago. Over the past few days, the strange (or rather illogical) feeling of wanted to go back to school has started kicking in. Without work or something to keep me busy, I think I get a bit lost&amp;hellip; So, while this break before school has been good, I am definitely ready to get back up and running again (both figuratively as well as actually physically running). I have a solid idea for my thesis, work lined up during my breaks (most likely),  and a whole lot of energy to push through the first 5 months of school with.&lt;/p&gt;

&lt;p&gt;Till next time folks!&lt;/p&gt;

&lt;p&gt;Also, if you haven&amp;rsquo;t already seen it, feel free to check out the house tour I put up on Youtube of the place I&amp;rsquo;m staying at in Seoul (video in this post)! Also please let me know if there is anything specific you would like to see and I will do my best to capture it and put it up!&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/AlltdoHwlhw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Drones, Friends, and Navigation</title>
      <link>https://kentsommer.xyz/blog/drones-friends-navigation/</link>
      <pubDate>Sun, 14 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/drones-friends-navigation/</guid>
      <description>&lt;p&gt;Wednesday came and went and once evening hit I realized I had to switch things up. I had been letting myself worry about every small thing that needed to happen once I was on campus and how difficult everything would be once there&amp;hellip; it was eating away at me. I&amp;rsquo;ve never felt homesick before, but this was as close as I would ever like to get again. I tried to remember back to my last trip here to figure out what was causing it and came to the conclusion that I wasn&amp;rsquo;t keeping myself nearly busy enough this time around. Two years ago it was wheels down at 8PM on a Sunday and work for a solid three months starting at 7AM the following Monday. So, I went into &amp;ldquo;recovery&amp;rdquo; mode and started scheduling things left, right, and center. I got to play &amp;ldquo;uncle&amp;rdquo; two times this week, the first with the niece of a now great friend, and the second with Daniel&amp;rsquo;s kids at the Drone Racing World Cup on Sunday. I can understand why someone would want to have kids if these types of interactions were the only ones they experienced. You don&amp;rsquo;t ever have to say no, the kids love you, and generally it is just a pretty great time!&lt;/p&gt;

&lt;p&gt;And now&amp;hellip; back to our regularly scheduled programming. Korea can be a beautiful and way less hectic place than you would ever think just visiting Seoul. I got to see scenic view after scenic view on my way down to the drone races on Sunday, mountains stretching up into the (what is probably pollution but let&amp;rsquo;s not worry too much about that) clouds in almost any direction you looked. Gone are the drab apartment buildings that stand to serve utility over all else and in its place a calm majestic landscape stretching as far as the eye can see. The day before this, I had the wonderful opportunity of visiting the Samsung Art Gallary which in a way almost prepared me for these new sights. Listening to the history behind each piece in the gallery, something I would normally find tedious, helped to place me in my new home. It also gave me a greater appreciation for the landscape of the trip I would take the following day.&lt;/p&gt;

&lt;p&gt;This past week I also experienced something I realized I didn&amp;rsquo;t really miss at all. Packed public transportation. The issue with making public transportation so cheap and reliable is that everyone starts to use it, try to catch one of the last trains home and suddenly you find yourself with no room to move your arms. Now hold that mental image, add 34c (93.2f) weather to the mix and it starts to get a lot less pleasant. About the only part of your body that the A/C hits is your hair, and while I&amp;rsquo;m no biological expert, I&amp;rsquo;m pretty sure it doesn&amp;rsquo;t benefit too much from being cool. Luckily, there is a simple solution to this issue&amp;hellip; don&amp;rsquo;t take the last train home. No matter if it is a Friday night or a Monday night it is guaranteed to be packed.&lt;/p&gt;

&lt;p&gt;Speaking of navigation topics, I&amp;rsquo;m always pleasantly surprised what a conversation with my mentors from Yujin Robot ( the company I worked at last time I was in Korea) will turn up, and catching up this week did not let me down on this front. The main topic was SLAM (simultaneous localization and mapping), but more specifically, wouldn&amp;rsquo;t it be better to model navigation off of a more human approach? As a person, we don&amp;rsquo;t tend to think about navigation by saying &amp;ldquo;I&amp;rsquo;m 12cm away from the right wall and I&amp;rsquo;ve gone 12m down this hallway, so in another 2m I will need to turn 45 degrees and then move 20cm before turning another 8 degrees and arriving at the elevator.&amp;rdquo; What if instead of this method you didn&amp;rsquo;t worry about tracking precise locations but rather approached it much more like a human? You don&amp;rsquo;t care where you are in a hallway when you know at the end of it is the elevator you will take up to the next floor. Simply enter some sort of hallway navigation mode and once you are at the end of the hallway determine roughly where you are. While this is an extremely simple example that removes a lot of complexity and potential stumbling blocks, it does make for an interesting proposition. This approach would rely heavily on place recognition for localization which while not a solved problem has recently seen huge advances due to the advances in convolutional neural networks. The more difficult portion would be determining what mapping would look like in this type of setup. By removing the unnatural precision placement you also lose the ability to do a probabilistic/statistical approach to SLAM. Is a SLAM approach like this possible? I have no idea. But where is the fun in already knowing an answer!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Things Started</title>
      <link>https://kentsommer.xyz/blog/getting-things-started/</link>
      <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/getting-things-started/</guid>
      <description>&lt;p&gt;As I write this, I&amp;rsquo;m happy to say I am finally here in Korea and gazing off at the mountain view from my residence in Seoul. I walked around a bit yesterday which ended up being very nostalgic as memories of late night ramen trips, daily bus rides, and familiar places came floating back to me. It almost feels like I never left&amp;hellip; Over the past 48 hours, one thing has become increasingly apparent, though, I really need to step up my studying game for Korean. After being able to speak and understand most of the Swedish conversation with all of my great friends the two weeks prior to this journey, not being able to understand almost anything here feels much more alienating than my last trip as I didn&amp;rsquo;t realize how much I was missing by not being able to speak the language. That being said I have an updated and significantly more aggressive plan of attack for the language and plan to be to the intermediate / low vocab semi-fluency level by this time next year. Hard? Yes. Doable? Absolutely!&lt;/p&gt;

&lt;p&gt;Last time I was here I ran into very few stumbling blocks, but since my trip is much longer, this time, I am finally getting to experience what I imagine it is like for someone to try to come to the US for school. That is lots of paperwork and a rather frustrating experience getting daily life things in order. Yesterday I went out fully expecting to get my bank account and phone plan setup, however, I came up feeling mildly defeated. It turns out that although I DO have an account still under my name from my trip two years ago, that account is on &amp;ldquo;hold&amp;rdquo; since I haven&amp;rsquo;t used it in over a year. And before you say &amp;ldquo;hey that&amp;rsquo;s great just show your passport / visa and get it re-opened,&amp;rdquo; I wish it was that simple. It turns out there have been some policy changes and due to this, I need proof of a need for a bank account. Being a student is ironically NOT an acceptable form of proof and instead, I would need to have a valid Alien Registration Card in order to open one. While this is somewhat of a non-issue as I have already signed up for my appointment with immigration to obtain one of these, it does put me in somewhat of a catch-22 for the next three weeks or so. Without the ARC (Alien Registration Card) I can&amp;rsquo;t get a bank account, without a bank account I can&amp;rsquo;t signup for phone service. Luckily having such great connections here has already paid off as I got some strings pulled and will be able to get a limited bank account setup which will allow me to signup for a phone plan on Monday.&lt;/p&gt;

&lt;p&gt;Before I sign off on this post, I want to apologize for the somewhat rambly writing, I whipped this out right before leaving for the day so it&amp;rsquo;s a bit off the cuff. Going forward I will try to stick to a once a week post on Saturdays with smaller posts during the week if there is anything I think is important enough to stand on its own. Please do leave comments and/or  those questions about Korea I know you have been dying to ask!&lt;/p&gt;

&lt;p&gt;Till next time!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Preparations and History</title>
      <link>https://kentsommer.xyz/blog/preparations-and-history/</link>
      <pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://kentsommer.xyz/blog/preparations-and-history/</guid>
      <description>&lt;p&gt;If I was asked to imagine four years ago where I would be today, never in my wildest dreams would I imagine myself here, yet, here I am, 50 days out from one of the biggest adventures of my life. In 50 short days, I will be boarding a plane for South Korea where I will be spending at least the next two years of my life. Now, this begs the question, how did I get here? Well, to answer that let me go back to a little over two years ago when I set foot in Korea for the first time.&lt;/p&gt;

&lt;p&gt;It was 6:00 PM and the plane had just landed at Incheon International Airport. I groggily made my way through security and picked up my bags after being awake for what felt like an eternity but was, in reality, only twenty-two hours or so. I was lucky enough to have a host family waiting for me right outside baggage claim and shortly thereafter (with the help of some coffee) found myself in the room I would call home for the next four months. Initially, I admit I was terrified&amp;hellip; new country, new people, a new language I couldn&amp;rsquo;t speak, new well&amp;hellip; everything. However, it didn&amp;rsquo;t take long before I started to realize that it was going to be hard to leave. Everything that was scary initially became everything I didn&amp;rsquo;t want to leave behind. Work was fascinating and sparked a new fire that would end up being the driving force for my decision to continue on to graduate studies after receiving my bachelor&amp;rsquo;s degree from the University of Minnesota. After returning home I knew I wanted to go back I just didn&amp;rsquo;t know how I would make it a reality. Quickly my mind turned to school again and I focused on my studies, however, this time, I focused on robotics and computer vision. Feeling like I finally found the field I wanted to spend my life exploring it was time to start thinking about the future. Looking back, I think it was incredibly short sighted of me to only apply to two graduate schools (KAIST and University of Helsinki), however, everything worked out somehow and I got into both. Having spent time in Korea and already hating the lack of sunlight during Minnesota&amp;rsquo;s winters I knew KAIST was where I wanted to spend the next leg of my academic journey.&lt;/p&gt;

&lt;p&gt;There is definitely a lot that still needs to be done. First and foremost, I need to actually figure what in the world to pack, two years is a long time and I&amp;rsquo;ve never been great a planning that far ahead. My Visa application still needs to be sent off among a myriad of other paperwork that I need to finish. While it all feels a little overwhelming at the moment, that doesn&amp;rsquo;t even begin to cast a shadow over the excitement of beginning life in a new country.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>